{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Анализ эксперимента по подстройке коэффициентов Kp и Ki от 25 ноября 2025\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Используется версия 4.0.0, в который были заменены все TorchRL компоненты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from pathlib import Path\n",
        "from nn_laser_stabilizer.config import load_config\n",
        "\n",
        "EXPERIMENT_DIR = Path(\"../experiments/pid_delta_tuning/2025-11-25_15-51-58\")\n",
        "CONFIG_PATH = EXPERIMENT_DIR / \"config.yaml\"\n",
        "ENV_LOG_PATH = EXPERIMENT_DIR / \"env_logs\" / \"env.log\"\n",
        "TRAIN_LOG_PATH = EXPERIMENT_DIR / \"logs\" / \"train.log\"\n",
        "CONNECTION_LOG_PATH = EXPERIMENT_DIR / \"connection_logs\" / \"connection.log\"\n",
        "\n",
        "config = load_config(CONFIG_PATH)\n",
        "print(f\"Эксперимент: {config.experiment_name}\")\n",
        "print(f\"Seed: {config.seed}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Анализ логов окружения\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_env_logs(file_path):\n",
        "    step_pattern = re.compile(\n",
        "        r\"step=(?P<step>\\d+)\\s+\"\n",
        "        r\"time=(?P<time>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kp=(?P<kp>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"ki=(?P<ki>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kd=(?P<kd>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"delta_kp_norm=(?P<delta_kp_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"delta_ki_norm=(?P<delta_ki_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_mean_norm=(?P<error_mean_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_std_norm=(?P<error_std_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"reward=(?P<reward>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"should_reset=(?P<should_reset>\\w+)\"\n",
        "    )\n",
        "    \n",
        "    reset_pattern = re.compile(\n",
        "        r\"reset\\s+time=(?P<time>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kp=(?P<kp>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"ki=(?P<ki>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kd=(?P<kd>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_mean_norm=(?P<error_mean_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_std_norm=(?P<error_std_norm>-?\\d+\\.\\d+)\"\n",
        "    )\n",
        "    \n",
        "    rows = []\n",
        "    reset_steps = []\n",
        "    current_step = 0\n",
        "    \n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            \n",
        "            reset_match = reset_pattern.match(line)\n",
        "            if reset_match:\n",
        "                reset_steps.append(current_step)\n",
        "                rows.append({\n",
        "                    'Step': current_step,\n",
        "                    'time': float(reset_match.group('time')),\n",
        "                    'Type': 'reset',\n",
        "                    'Kp': float(reset_match.group('kp')),\n",
        "                    'Ki': float(reset_match.group('ki')),\n",
        "                    'Kd': float(reset_match.group('kd')),\n",
        "                    'Delta Kp': np.nan,\n",
        "                    'Delta Ki': np.nan,\n",
        "                    'Error mean norm': float(reset_match.group('error_mean_norm')),\n",
        "                    'Error std norm': float(reset_match.group('error_std_norm')),\n",
        "                    'Reward': np.nan,\n",
        "                    'Should reset': True\n",
        "                })\n",
        "                continue\n",
        "            \n",
        "            step_match = step_pattern.match(line)\n",
        "            if step_match:\n",
        "                current_step = int(step_match.group('step'))\n",
        "                should_reset = step_match.group('should_reset').lower() == 'true'\n",
        "                \n",
        "                rows.append({\n",
        "                    'Step': current_step,\n",
        "                    'time': float(step_match.group('time')),\n",
        "                    'Type': 'step',\n",
        "                    'Kp': float(step_match.group('kp')),\n",
        "                    'Ki': float(step_match.group('ki')),\n",
        "                    'Kd': float(step_match.group('kd')),\n",
        "                    'Delta Kp': float(step_match.group('delta_kp_norm')),\n",
        "                    'Delta Ki': float(step_match.group('delta_ki_norm')),\n",
        "                    'Error mean norm': float(step_match.group('error_mean_norm')),\n",
        "                    'Error std norm': float(step_match.group('error_std_norm')),\n",
        "                    'Reward': float(step_match.group('reward')),\n",
        "                    'Should reset': should_reset\n",
        "                })\n",
        "    \n",
        "    return pd.DataFrame(rows), reset_steps\n",
        "\n",
        "env_df, reset_steps = parse_env_logs(ENV_LOG_PATH)\n",
        "print(f\"Загружено {len(env_df)} записей из логов окружения\")\n",
        "print(f\"Найдено {len(reset_steps)} reset событий\")\n",
        "print(f\"Диапазон шагов: {env_df['Step'].min()} - {env_df['Step'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "step_df = env_df[env_df['Type'] == 'step'].copy()\n",
        "print(\"=== Статистика по шагам окружения ===\")\n",
        "print(step_df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exploration_steps = config.training.exploration_steps\n",
        "initial_collect_steps = config.training.initial_collect_steps\n",
        "neural_network_step = max(initial_collect_steps, exploration_steps)\n",
        "\n",
        "columns_to_plot = ['Kp', 'Ki', 'Error mean norm', 'Error std norm', 'Reward']\n",
        "\n",
        "for col in columns_to_plot:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(step_df['Step'], step_df[col], alpha=0.8, linewidth=0.8, label=col)\n",
        "    \n",
        "    for reset_step in reset_steps:\n",
        "        if reset_step <= step_df['Step'].max():\n",
        "            plt.axvline(x=reset_step, color='orange', linestyle=':', linewidth=1, alpha=0.5)\n",
        "    \n",
        "    if neural_network_step <= step_df['Step'].max():\n",
        "        plt.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2, \n",
        "                    label=f'Switch to NN (step {neural_network_step})')\n",
        "    \n",
        "    plt.title(f'{col} over Steps')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel(col)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nn_step_df = step_df[step_df['Step'] >= neural_network_step].copy()\n",
        "\n",
        "if len(nn_step_df) > 0:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(nn_step_df['Step'], nn_step_df['Error std norm'], alpha=0.8, linewidth=0.8)\n",
        "    \n",
        "    for reset_step in reset_steps:\n",
        "        if reset_step >= neural_network_step and reset_step <= nn_step_df['Step'].max():\n",
        "            plt.axvline(x=reset_step, color='orange', linestyle=':', linewidth=1, alpha=0.5, label='Reset' if reset_step == reset_steps[0] else '')\n",
        "    \n",
        "    plt.title('Error std norm over Steps (NN phase)')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Error std norm')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "cur_ax = axes[0]\n",
        "sns.scatterplot(x=step_df['Kp'], y=step_df['Error std norm'], alpha=0.6, ax=cur_ax)\n",
        "cur_ax.set_xlabel('Kp')\n",
        "cur_ax.set_ylabel('Error Std Norm')\n",
        "cur_ax.grid(True, alpha=0.3)\n",
        "\n",
        "cur_ax = axes[1]\n",
        "sns.scatterplot(x=step_df['Kp'], y=step_df['Error mean norm'], alpha=0.6, ax=cur_ax, color='orange')\n",
        "cur_ax.set_xlabel('Kp')\n",
        "cur_ax.set_ylabel('Error mean norm')\n",
        "cur_ax.grid(True, alpha=0.3)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "cur_ax = axes[0]\n",
        "sns.scatterplot(x=step_df['Ki'], y=step_df['Error std norm'], alpha=0.6, ax=cur_ax)\n",
        "cur_ax.set_xlabel('Ki')\n",
        "cur_ax.set_ylabel('Error Std Norm')\n",
        "cur_ax.grid(True, alpha=0.3)\n",
        "\n",
        "cur_ax = axes[1]\n",
        "sns.scatterplot(x=step_df['Ki'], y=step_df['Error mean norm'], alpha=0.6, ax=cur_ax, color='orange')\n",
        "cur_ax.set_xlabel('Ki')\n",
        "cur_ax.set_ylabel('Error mean norm')\n",
        "cur_ax.grid(True, alpha=0.3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix = step_df[['Kp', 'Ki', 'Error mean norm', 'Error std norm', 'Reward']].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Анализ процесса обучения\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_train_logs(file_path):\n",
        "    pattern = re.compile(\n",
        "        r\"step=(?P<step>\\d+)\\s+\"\n",
        "        r\"time=(?P<time>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"loss_q1=(?P<loss_q1>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"loss_q2=(?P<loss_q2>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"(actor_loss=(?P<actor_loss>-?\\d+\\.\\d+)\\s+)?\"\n",
        "        r\"buffer_size=(?P<buffer_size>\\d+)\"\n",
        "    )\n",
        "    \n",
        "    rows = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            match = pattern.match(line)\n",
        "            if match:\n",
        "                actor_loss = match.group('actor_loss')\n",
        "                rows.append({\n",
        "                    'step': int(match.group('step')),\n",
        "                    'loss_q1': float(match.group('loss_q1')),\n",
        "                    'loss_q2': float(match.group('loss_q2')),\n",
        "                    'actor_loss': float(actor_loss) if actor_loss else np.nan,\n",
        "                    'buffer_size': int(match.group('buffer_size'))\n",
        "                })\n",
        "    \n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "loss_df = parse_train_logs(TRAIN_LOG_PATH)\n",
        "print(f\"Загружено {len(loss_df)} записей из логов обучения\")\n",
        "print(f\"Диапазон шагов обучения: {loss_df['step'].min()} - {loss_df['step'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
        "\n",
        "axes[0].plot(loss_df['step'], loss_df['loss_q1'], 'b-', alpha=0.7, label='Q1 Loss')\n",
        "axes[0].set_title('Q1 Loss')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_yscale('log')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(loss_df['step'], loss_df['loss_q2'], 'g-', alpha=0.7, label='Q2 Loss')\n",
        "axes[1].set_title('Q2 Loss')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].set_yscale('log')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].plot(loss_df['step'], loss_df['loss_q1'] + loss_df['loss_q2'], 'r--', alpha=0.7, label='Sum (Q1 + Q2)')\n",
        "axes[2].set_title('Sum (Q1 + Q2)')\n",
        "axes[2].set_xlabel('Step')\n",
        "axes[2].set_ylabel('Loss')\n",
        "axes[2].set_yscale('log')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "actor_loss_df = loss_df[loss_df['actor_loss'].notna()]\n",
        "if len(actor_loss_df) > 0:\n",
        "    plt.plot(actor_loss_df['step'], actor_loss_df['actor_loss'], 'r-', alpha=0.7)\n",
        "    plt.title('Actor Loss')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'No actor loss data', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Actor Loss (no data)')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(loss_df['step'], loss_df['buffer_size'], 'm-', alpha=0.7)\n",
        "plt.title('Buffer Size')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Size')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Анализ состояния установки\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_connection_logs(file_path):\n",
        "    send_pattern = re.compile(r\"SEND: kp=(?P<kp>-?\\d+\\.\\d+) ki=(?P<ki>-?\\d+\\.\\d+) kd=(?P<kd>-?\\d+\\.\\d+) control_min=(?P<control_min>\\d+) control_max=(?P<control_max>\\d+)\")\n",
        "    read_pattern = re.compile(r\"READ: process_variable=(?P<process_variable>-?\\d+\\.\\d+) control_output=(?P<control_output>-?\\d+\\.\\d+)\")\n",
        "    \n",
        "    send_rows = []\n",
        "    read_rows = []\n",
        "    step = 0\n",
        "    \n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            \n",
        "            send_match = send_pattern.match(line)\n",
        "            if send_match:\n",
        "                send_rows.append({\n",
        "                    'step': step,\n",
        "                    'type': 'SEND',\n",
        "                    'kp': float(send_match.group('kp')),\n",
        "                    'ki': float(send_match.group('ki')),\n",
        "                    'kd': float(send_match.group('kd')),\n",
        "                    'control_min': int(send_match.group('control_min')),\n",
        "                    'control_max': int(send_match.group('control_max'))\n",
        "                })\n",
        "                step += 1\n",
        "            \n",
        "            read_match = read_pattern.match(line)\n",
        "            if read_match:\n",
        "                read_rows.append({\n",
        "                    'step': step - 1,\n",
        "                    'type': 'READ',\n",
        "                    'process_variable': float(read_match.group('process_variable')),\n",
        "                    'control_output': float(read_match.group('control_output'))\n",
        "                })\n",
        "    \n",
        "    connection_df = pd.DataFrame(send_rows)\n",
        "    read_df = pd.DataFrame(read_rows)\n",
        "    \n",
        "    if not connection_df.empty and not read_df.empty:\n",
        "        connection_df = connection_df.merge(read_df[['step', 'process_variable', 'control_output']], \n",
        "                                          on='step', how='left')\n",
        "    \n",
        "    return connection_df\n",
        "\n",
        "connection_df = parse_connection_logs(CONNECTION_LOG_PATH)\n",
        "print(f\"Загружено {len(connection_df)} записей из логов соединения\")\n",
        "if len(connection_df) > 0:\n",
        "    print(f\"Диапазон шагов: {connection_df['step'].min()} - {connection_df['step'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neural_network_step = max(initial_collect_steps, exploration_steps) * config.env.args.block_size\n",
        "if len(connection_df) > 0:\n",
        "    setpoint = config.env.args.setpoint\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(connection_df['step'], connection_df['process_variable'], 'b-', alpha=0.7, linewidth=0.8, label='Process Variable')\n",
        "    plt.axhline(y=setpoint, color='r', linestyle='--', label=f'Setpoint ({setpoint})')\n",
        "    \n",
        "    for reset_step in reset_steps:\n",
        "        if reset_step <= connection_df['step'].max():\n",
        "            plt.axvline(x=reset_step, color='orange', linestyle=':', linewidth=1, alpha=0.5)\n",
        "    \n",
        "    if neural_network_step <= connection_df['step'].max():\n",
        "        plt.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2, \n",
        "                    label=f'Switch to NN (step {neural_network_step})')\n",
        "    \n",
        "    plt.title('Process Variable')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylim(500, 1700)\n",
        "    plt.ylabel('Process Variable')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(connection_df['step'], connection_df['control_output'], 'g-', alpha=0.7, linewidth=0.8, label='Control Output')\n",
        "    \n",
        "    for reset_step in reset_steps:\n",
        "        if reset_step <= connection_df['step'].max():\n",
        "            plt.axvline(x=reset_step, color='orange', linestyle=':', linewidth=1, alpha=0.5)\n",
        "    \n",
        "    if neural_network_step <= connection_df['step'].max():\n",
        "        plt.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2, \n",
        "                    label=f'Switch to NN (step {neural_network_step})')\n",
        "    \n",
        "    plt.title('Control Output')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Control Output')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(connection_df['step'], connection_df['kp'], 'r-', alpha=0.7, linewidth=0.8, label='Kp')\n",
        "    plt.plot(connection_df['step'], connection_df['ki'], 'g-', alpha=0.7, linewidth=0.8, label='Ki')\n",
        "    plt.plot(connection_df['step'], connection_df['kd'], 'b-', alpha=0.7, linewidth=0.8, label='Kd')\n",
        "    \n",
        "    for reset_step in reset_steps:\n",
        "        if reset_step <= connection_df['step'].max():\n",
        "            plt.axvline(x=reset_step, color='orange', linestyle=':', linewidth=1, alpha=0.5)\n",
        "    \n",
        "    if neural_network_step <= connection_df['step'].max():\n",
        "        plt.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2, \n",
        "                    label=f'Switch to NN (step {neural_network_step})')\n",
        "    \n",
        "    plt.title('PID Coefficients')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Coefficient Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(connection_df) > 0:\n",
        "    corr_matrix = connection_df[['kp', 'ki', 'control_output', 'process_variable']].corr()\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title('Correlation Matrix (Connection Data)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "step_df = step_df.sort_values('time')\n",
        "step_df['time_diff'] = step_df['time'].diff()\n",
        "step_df['time_diff_ms'] = step_df['time_diff'] * 1000 \n",
        "if len(step_df) > 0:\n",
        "    step_df['time_relative'] = step_df['time'] - step_df['time'].iloc[0]\n",
        "    step_df['time_relative_minutes'] = step_df['time_relative'] / 60\n",
        "\n",
        "time_df, step_time_df = env_df.copy(), step_df.copy()\n",
        "\n",
        "print(\"=== Статистика по времени ===\")\n",
        "print(f\"Всего записей: {len(time_df)}\")\n",
        "print(f\"Шагов: {len(time_df[time_df['Type'] == 'step'])}\")\n",
        "print(f\"Reset событий: {len(time_df[time_df['Type'] == 'reset'])}\")\n",
        "\n",
        "if len(step_time_df) > 0:\n",
        "    print(f\"\\n=== Статистика интервалов между шагами ===\")\n",
        "    print(step_time_df['time_diff_ms'].describe())\n",
        "    print(f\"\\nМедианный интервал: {step_time_df['time_diff_ms'].median():.2f} мс\")\n",
        "    print(f\"Средний интервал: {step_time_df['time_diff_ms'].mean():.2f} мс\")\n",
        "    print(f\"Максимальный интервал: {step_time_df['time_diff_ms'].max():.2f} мс\")\n",
        "    print(f\"Минимальный интервал: {step_time_df['time_diff_ms'].min():.2f} мс\")\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(step_time_df['Step'], step_time_df['time_diff_ms'], 'b-', alpha=0.7, linewidth=0.8)\n",
        "    plt.title('Time Intervals Between Steps')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Time Interval (ms)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.hist(step_time_df['time_diff_ms'].dropna(), bins=50, alpha=0.7, edgecolor='black')\n",
        "    plt.title('Distribution of Time Intervals Between Steps')\n",
        "    plt.xlabel('Time Interval (ms)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nn-laser-stabilizer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
