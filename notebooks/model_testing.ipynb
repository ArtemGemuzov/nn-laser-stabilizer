{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Тестирование моделей актора и критика\n",
        "\n",
        "Этот ноутбук позволяет загружать обученные модели актора и критика по имени эксперимента и тестировать их на фиксированных входных данных.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Optional, Dict, Any\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "\n",
        "from nn_laser_stabilizer.agents.td3 import make_td3_agent, warmup_from_specs\n",
        "from nn_laser_stabilizer.envs.utils import make_specs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Функции для загрузки моделей\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_experiment_path(experiment_name: str, date: str, time: str) -> Path:\n",
        "    \"\"\"\n",
        "    Находит путь к эксперименту по имени, дате и времени.\n",
        "    \n",
        "    Args:\n",
        "        experiment_name: Имя эксперимента (например, 'td3_train_simulation')\n",
        "        date: Дата в формате YYYY-MM-DD (опционально)\n",
        "        time: Время в формате HH-MM-SS (опционально)\n",
        "    \n",
        "    Returns:\n",
        "        Path к директории эксперимента\n",
        "    \"\"\"\n",
        "    experiments_dir = Path(\"../experiments\")\n",
        "    \n",
        "    if not experiments_dir.exists():\n",
        "        raise FileNotFoundError(f\"Директория экспериментов не найдена: {experiments_dir}\")\n",
        "    \n",
        "    exp_dir = experiments_dir / experiment_name\n",
        "    \n",
        "    if not exp_dir.exists():\n",
        "        raise FileNotFoundError(f\"Эксперимент не найден: {experiment_name}\")\n",
        "    \n",
        "    date_dir = exp_dir / date\n",
        "    \n",
        "    if not date_dir.exists():\n",
        "        raise FileNotFoundError(f\"Дата не найдена: {date}\")\n",
        "    \n",
        "    time_dir = date_dir / time\n",
        "    \n",
        "    if not time_dir.exists():\n",
        "        raise FileNotFoundError(f\"Время не найдено: {time}\")\n",
        "    \n",
        "    return time_dir\n",
        "\n",
        "def load_experiment_config(experiment_path: Path) -> DictConfig:\n",
        "    \"\"\"\n",
        "    Загружает конфигурацию эксперимента.\n",
        "    \n",
        "    Args:\n",
        "        experiment_path: Путь к директории эксперимента\n",
        "    \n",
        "    Returns:\n",
        "        Конфигурация эксперимента\n",
        "    \"\"\"\n",
        "    config_path = experiment_path / \".hydra\" / \"config.yaml\"\n",
        "    \n",
        "    if config_path.exists():\n",
        "        return OmegaConf.load(config_path)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Файл конфигурации не найден: {config_path}\")\n",
        "\n",
        "def load_models(experiment_name: str, date: Optional[str] = None, time: Optional[str] = None, \n",
        "                device: str = \"cpu\") -> Tuple[torch.nn.Module, torch.nn.Module, DictConfig]:\n",
        "    \"\"\"\n",
        "    Загружает модели актора и критика из эксперимента.\n",
        "    \n",
        "    Args:\n",
        "        experiment_name: Имя эксперимента\n",
        "        date: Дата эксперимента (опционально)\n",
        "        time: Время эксперимента (опционально)\n",
        "        device: Устройство для загрузки моделей\n",
        "    \n",
        "    Returns:\n",
        "        Кортеж (actor, critic, config)\n",
        "    \"\"\"\n",
        "    # Находим путь к эксперименту\n",
        "    experiment_path = find_experiment_path(experiment_name, date, time)\n",
        "    print(f\"Загружаем модели из: {experiment_path}\")\n",
        "    \n",
        "    # Загружаем конфигурацию\n",
        "    config = load_experiment_config(experiment_path)\n",
        "    print(f\"Конфигурация загружена: {config.experiment_name}\")\n",
        "    \n",
        "    # Получаем спецификации из конфигурации\n",
        "    specs = make_specs(config.env.bounds)\n",
        "    action_spec = specs[\"action\"]\n",
        "    observation_spec = specs[\"observation\"]\n",
        "    \n",
        "    # Создаем модели\n",
        "    actor, critic = make_td3_agent(config, observation_spec, action_spec)\n",
        "    \n",
        "    # Загружаем веса моделей\n",
        "    saved_models_dir = experiment_path / \"saved_models\"\n",
        "    \n",
        "    if saved_models_dir.exists():\n",
        "        actor_path = saved_models_dir / \"actor.pth\"\n",
        "        critic_path = saved_models_dir / \"qvalue.pth\"\n",
        "        \n",
        "        if actor_path.exists():\n",
        "            actor.load_state_dict(torch.load(actor_path, map_location=device))\n",
        "            print(f\"Актор загружен из: {actor_path}\")\n",
        "        else:\n",
        "            print(f\"Файл актора не найден: {actor_path}\")\n",
        "        \n",
        "        if critic_path.exists():\n",
        "            critic.load_state_dict(torch.load(critic_path, map_location=device))\n",
        "            print(f\"Критик загружен из: {critic_path}\")\n",
        "        else:\n",
        "            print(f\"Файл критика не найден: {critic_path}\")\n",
        "    else:\n",
        "        print(f\"Директория с сохраненными моделями не найдена: {saved_models_dir}\")\n",
        "        print(\"Используются случайно инициализированные веса\")\n",
        "    \n",
        "    # Переводим модели на нужное устройство\n",
        "    actor = actor.to(device)\n",
        "    critic = critic.to(device)\n",
        "    \n",
        "    # Выполняем warmup\n",
        "    warmup_from_specs(observation_spec, action_spec, actor, critic, device)\n",
        "    \n",
        "    return actor, critic, config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Функции для тестирования моделей\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_actor(actor: torch.nn.Module, observations: torch.Tensor, device: str = \"cpu\") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Тестирует актора на заданных наблюдениях.\n",
        "    \n",
        "    Args:\n",
        "        actor: Модель актора\n",
        "        observations: Тензор наблюдений [batch_size, obs_dim]\n",
        "        device: Устройство для вычислений\n",
        "    \n",
        "    Returns:\n",
        "        Тензор действий [batch_size, action_dim]\n",
        "    \"\"\"\n",
        "    actor.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # Создаем TensorDict для актора\n",
        "        from tensordict import TensorDict\n",
        "        from torchrl.envs import set_exploration_type, ExplorationType\n",
        "        \n",
        "        batch_size = observations.shape[0]\n",
        "        td = TensorDict({\n",
        "            \"observation\": observations.to(device),\n",
        "            \"is_init\": torch.ones(batch_size, dtype=torch.bool, device=device)\n",
        "        }, batch_size=[batch_size])\n",
        "        \n",
        "        # Получаем действия в детерминированном режиме\n",
        "        with set_exploration_type(ExplorationType.DETERMINISTIC):\n",
        "            actions = actor(td)[\"action\"]\n",
        "    \n",
        "    return actions\n",
        "\n",
        "def test_critic(critic: torch.nn.Module, observations: torch.Tensor, actions: torch.Tensor, \n",
        "                device: str = \"cpu\") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Тестирует критика на заданных наблюдениях и действиях.\n",
        "    \n",
        "    Args:\n",
        "        critic: Модель критика\n",
        "        observations: Тензор наблюдений [batch_size, obs_dim]\n",
        "        actions: Тензор действий [batch_size, action_dim]\n",
        "        device: Устройство для вычислений\n",
        "    \n",
        "    Returns:\n",
        "        Тензор Q-значений [batch_size, 1]\n",
        "    \"\"\"\n",
        "    critic.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # Создаем TensorDict для критика\n",
        "        from tensordict import TensorDict\n",
        "        \n",
        "        batch_size = observations.shape[0]\n",
        "        td = TensorDict({\n",
        "            \"observation\": observations.to(device),\n",
        "            \"action\": actions.to(device),\n",
        "            \"is_init\": torch.ones(batch_size, dtype=torch.bool, device=device)\n",
        "        }, batch_size=[batch_size])\n",
        "        \n",
        "        # Получаем Q-значения\n",
        "        q_values = critic(td)[\"state_action_value\"]\n",
        "    \n",
        "    return q_values\n",
        "\n",
        "def generate_test_data(observation_spec, action_spec, num_samples: int = 10, \n",
        "                      device: str = \"cpu\") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Генерирует тестовые данные для моделей.\n",
        "    \n",
        "    Args:\n",
        "        observation_spec: Спецификация наблюдений\n",
        "        action_spec: Спецификация действий\n",
        "        num_samples: Количество тестовых образцов\n",
        "        device: Устройство для тензоров\n",
        "    \n",
        "    Returns:\n",
        "        Кортеж (observations, actions)\n",
        "    \"\"\"\n",
        "    # Генерируем случайные наблюдения в пределах спецификации\n",
        "    obs_shape = (num_samples,) + observation_spec.shape\n",
        "    observations = torch.rand(obs_shape, device=device) * (observation_spec.space.high - observation_spec.space.low) + observation_spec.space.low\n",
        "    \n",
        "    # Генерируем случайные действия в пределах спецификации\n",
        "    action_shape = (num_samples,) + action_spec.shape\n",
        "    actions = torch.rand(action_shape, device=device) * (action_spec.space.high - action_spec.space.low) + action_spec.space.low\n",
        "    \n",
        "    return observations, actions\n",
        "\n",
        "def test_models_comprehensive(actor: torch.nn.Module, critic: torch.nn.Module, \n",
        "                            observation_spec, action_spec, num_samples: int = 10,\n",
        "                            device: str = \"cpu\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Комплексное тестирование моделей актора и критика.\n",
        "    \n",
        "    Args:\n",
        "        actor: Модель актора\n",
        "        critic: Модель критика\n",
        "        observation_spec: Спецификация наблюдений\n",
        "        action_spec: Спецификация действий\n",
        "        num_samples: Количество тестовых образцов\n",
        "        device: Устройство для вычислений\n",
        "    \n",
        "    Returns:\n",
        "        Словарь с результатами тестирования\n",
        "    \"\"\"\n",
        "    print(f\"Тестируем модели на {num_samples} образцах...\")\n",
        "    \n",
        "    # Генерируем тестовые данные\n",
        "    observations, random_actions = generate_test_data(observation_spec, action_spec, num_samples, device)\n",
        "    \n",
        "    # Тестируем актора\n",
        "    actor_actions = test_actor(actor, observations, device)\n",
        "    \n",
        "    # Тестируем критика с действиями от актора\n",
        "    critic_q_values_actor = test_critic(critic, observations, actor_actions, device)\n",
        "    \n",
        "    # Тестируем критика со случайными действиями\n",
        "    critic_q_values_random = test_critic(critic, observations, random_actions, device)\n",
        "    \n",
        "    results = {\n",
        "        \"observations\": observations,\n",
        "        \"actor_actions\": actor_actions,\n",
        "        \"random_actions\": random_actions,\n",
        "        \"critic_q_values_actor\": critic_q_values_actor,\n",
        "        \"critic_q_values_random\": critic_q_values_random,\n",
        "        \"num_samples\": num_samples\n",
        "    }\n",
        "    \n",
        "    # Выводим статистику\n",
        "    print(f\"\\nСтатистика актора:\")\n",
        "    print(f\"  Среднее действие: {actor_actions.mean(dim=0)}\")\n",
        "    print(f\"  Стандартное отклонение: {actor_actions.std(dim=0)}\")\n",
        "    print(f\"  Минимум: {actor_actions.min(dim=0)[0]}\")\n",
        "    print(f\"  Максимум: {actor_actions.max(dim=0)[0]}\")\n",
        "    \n",
        "    print(f\"\\nСтатистика критика (действия от актора):\")\n",
        "    print(f\"  Среднее Q-значение: {critic_q_values_actor.mean():.4f}\")\n",
        "    print(f\"  Стандартное отклонение: {critic_q_values_actor.std():.4f}\")\n",
        "    print(f\"  Минимум: {critic_q_values_actor.min():.4f}\")\n",
        "    print(f\"  Максимум: {critic_q_values_actor.max():.4f}\")\n",
        "    \n",
        "    print(f\"\\nСтатистика критика (случайные действия):\")\n",
        "    print(f\"  Среднее Q-значение: {critic_q_values_random.mean():.4f}\")\n",
        "    print(f\"  Стандартное отклонение: {critic_q_values_random.std():.4f}\")\n",
        "    print(f\"  Минимум: {critic_q_values_random.min():.4f}\")\n",
        "    print(f\"  Максимум: {critic_q_values_random.max():.4f}\")\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Функции для визуализации результатов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_test_results(results: Dict[str, Any], title: str = \"Результаты тестирования моделей\"):\n",
        "    \"\"\"\n",
        "    Визуализирует результаты тестирования моделей.\n",
        "    \n",
        "    Args:\n",
        "        results: Словарь с результатами тестирования\n",
        "        title: Заголовок графика\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "    \n",
        "    observations = results[\"observations\"]\n",
        "    actor_actions = results[\"actor_actions\"]\n",
        "    random_actions = results[\"random_actions\"]\n",
        "    critic_q_values_actor = results[\"critic_q_values_actor\"]\n",
        "    critic_q_values_random = results[\"critic_q_values_random\"]\n",
        "    \n",
        "    # График 1: Действия актора\n",
        "    axes[0, 0].plot(actor_actions.cpu().numpy())\n",
        "    axes[0, 0].set_title(\"Действия актора\")\n",
        "    axes[0, 0].set_xlabel(\"Образец\")\n",
        "    axes[0, 0].set_ylabel(\"Значение действия\")\n",
        "    axes[0, 0].legend([f\"Действие {i}\" for i in range(actor_actions.shape[1])])\n",
        "    axes[0, 0].grid(True)\n",
        "    \n",
        "    # График 2: Q-значения критика\n",
        "    axes[0, 1].plot(critic_q_values_actor.cpu().numpy(), label=\"Действия от актора\", alpha=0.7)\n",
        "    axes[0, 1].plot(critic_q_values_random.cpu().numpy(), label=\"Случайные действия\", alpha=0.7)\n",
        "    axes[0, 1].set_title(\"Q-значения критика\")\n",
        "    axes[0, 1].set_xlabel(\"Образец\")\n",
        "    axes[0, 1].set_ylabel(\"Q-значение\")\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "    \n",
        "    # График 3: Распределение действий актора\n",
        "    for i in range(actor_actions.shape[1]):\n",
        "        axes[1, 0].hist(actor_actions[:, i].cpu().numpy(), alpha=0.7, label=f\"Действие {i}\")\n",
        "    axes[1, 0].set_title(\"Распределение действий актора\")\n",
        "    axes[1, 0].set_xlabel(\"Значение действия\")\n",
        "    axes[1, 0].set_ylabel(\"Частота\")\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True)\n",
        "    \n",
        "    # График 4: Сравнение Q-значений\n",
        "    axes[1, 1].scatter(critic_q_values_actor.cpu().numpy(), critic_q_values_random.cpu().numpy(), alpha=0.7)\n",
        "    axes[1, 1].plot([critic_q_values_actor.min(), critic_q_values_actor.max()], \n",
        "                    [critic_q_values_actor.min(), critic_q_values_actor.max()], 'r--', alpha=0.5)\n",
        "    axes[1, 1].set_title(\"Сравнение Q-значений\")\n",
        "    axes[1, 1].set_xlabel(\"Q-значение (действия от актора)\")\n",
        "    axes[1, 1].set_ylabel(\"Q-значение (случайные действия)\")\n",
        "    axes[1, 1].grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def compare_experiments(experiment_results: Dict[str, Dict[str, Any]]):\n",
        "    \"\"\"\n",
        "    Сравнивает результаты нескольких экспериментов.\n",
        "    \n",
        "    Args:\n",
        "        experiment_results: Словарь с результатами экспериментов\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle(\"Сравнение экспериментов\", fontsize=16)\n",
        "    \n",
        "    experiment_names = list(experiment_results.keys())\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(experiment_names)))\n",
        "    \n",
        "    # График 1: Средние Q-значения для действий от актора\n",
        "    mean_q_actor = []\n",
        "    for name in experiment_names:\n",
        "        mean_q_actor.append(experiment_results[name][\"critic_q_values_actor\"].mean().item())\n",
        "    \n",
        "    axes[0, 0].bar(experiment_names, mean_q_actor, color=colors)\n",
        "    axes[0, 0].set_title(\"Средние Q-значения (действия от актора)\")\n",
        "    axes[0, 0].set_ylabel(\"Q-значение\")\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # График 2: Средние Q-значения для случайных действий\n",
        "    mean_q_random = []\n",
        "    for name in experiment_names:\n",
        "        mean_q_random.append(experiment_results[name][\"critic_q_values_random\"].mean().item())\n",
        "    \n",
        "    axes[0, 1].bar(experiment_names, mean_q_random, color=colors)\n",
        "    axes[0, 1].set_title(\"Средние Q-значения (случайные действия)\")\n",
        "    axes[0, 1].set_ylabel(\"Q-значение\")\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # График 3: Разброс действий актора\n",
        "    action_std = []\n",
        "    for name in experiment_names:\n",
        "        action_std.append(experiment_results[name][\"actor_actions\"].std().mean().item())\n",
        "    \n",
        "    axes[1, 0].bar(experiment_names, action_std, color=colors)\n",
        "    axes[1, 0].set_title(\"Средний разброс действий актора\")\n",
        "    axes[1, 0].set_ylabel(\"Стандартное отклонение\")\n",
        "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # График 4: Разность Q-значений (актор vs случайные)\n",
        "    q_diff = []\n",
        "    for name in experiment_names:\n",
        "        diff = (experiment_results[name][\"critic_q_values_actor\"].mean() - \n",
        "                experiment_results[name][\"critic_q_values_random\"].mean()).item()\n",
        "        q_diff.append(diff)\n",
        "    \n",
        "    axes[1, 1].bar(experiment_names, q_diff, color=colors)\n",
        "    axes[1, 1].set_title(\"Разность Q-значений (актор - случайные)\")\n",
        "    axes[1, 1].set_ylabel(\"Разность Q-значений\")\n",
        "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "    axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Тестирование конкретных экспериментов\n",
        "\n",
        "Тестируем модели из экспериментов от 2025-09-24:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Параметры экспериментов\n",
        "EXPERIMENT_DATE = \"2025-09-24\"\n",
        "EXPERIMENTS = {\n",
        "    \"relative_skip1\": {\n",
        "        \"time\": \"18-31-57\",\n",
        "    },\n",
        "    \"relative_skip50\": {\n",
        "        \"time\": \"18-52-01\",\n",
        "    },\n",
        "    \"absolute_skip50\": {\n",
        "        \"time\": \"18-14-49\",\n",
        "    },\n",
        "}\n",
        "\n",
        "# Устройство для вычислений\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Используемое устройство: {device}\")\n",
        "\n",
        "# Количество тестовых образцов\n",
        "num_test_samples = 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загружаем и тестируем модели для каждого эксперимента\n",
        "experiment_results = {}\n",
        "loaded_models = {}\n",
        "\n",
        "for exp_name, exp_info in EXPERIMENTS.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Тестируем эксперимент: {exp_name}\")\n",
        "    print(f\"Дата: {EXPERIMENT_DATE}, Время: {exp_info['time']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    try:\n",
        "        # Загружаем модели\n",
        "        actor, critic, config = load_models(\n",
        "            experiment_name=exp_name,\n",
        "            date=EXPERIMENT_DATE,\n",
        "            time=exp_info['time'],\n",
        "            device=device\n",
        "        )\n",
        "        \n",
        "        # Сохраняем загруженные модели\n",
        "        loaded_models[exp_name] = {\n",
        "            'actor': actor,\n",
        "            'critic': critic,\n",
        "            'config': config\n",
        "        }\n",
        "        \n",
        "        # Получаем спецификации из конфигурации\n",
        "        specs = make_specs(config.env.bounds)\n",
        "        action_spec = specs[\"action\"]\n",
        "        observation_spec = specs[\"observation\"]\n",
        "        \n",
        "        # Тестируем модели\n",
        "        results = test_models_comprehensive(\n",
        "            actor=actor,\n",
        "            critic=critic,\n",
        "            observation_spec=observation_spec,\n",
        "            action_spec=action_spec,\n",
        "            num_samples=num_test_samples,\n",
        "            device=device\n",
        "        )\n",
        "        \n",
        "        # Сохраняем результаты\n",
        "        experiment_results[exp_name] = results\n",
        "        \n",
        "        print(f\"✅ Эксперимент {exp_name} успешно протестирован\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Ошибка при тестировании эксперимента {exp_name}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Завершено тестирование {len(experiment_results)} экспериментов\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Визуализация результатов\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализируем результаты для каждого эксперимента\n",
        "if experiment_results:\n",
        "    for exp_name, results in experiment_results.items():\n",
        "        print(f\"\\nВизуализация результатов для эксперимента: {exp_name}\")\n",
        "        plot_test_results(results, title=f\"Результаты тестирования: {exp_name}\")\n",
        "else:\n",
        "    print(\"Нет результатов для визуализации\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сравниваем результаты всех экспериментов\n",
        "if len(experiment_results) > 1:\n",
        "    print(\"\\nСравнение всех экспериментов:\")\n",
        "    compare_experiments(experiment_results)\n",
        "else:\n",
        "    print(\"Недостаточно экспериментов для сравнения\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Тестирование с фиксированными входными данными\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Тестируем модели на фиксированных входных данных\n",
        "if loaded_models:\n",
        "    print(\"Тестирование на фиксированных входных данных:\")\n",
        "    \n",
        "    # Создаем фиксированные тестовые данные (соответствуют спецификациям реальной среды)\n",
        "    # Наблюдения: [ADC_value, DAC_value, setpoint] в диапазоне [0, 10230] для ADC и setpoint, [0, 4095] для DAC\n",
        "    fixed_observations = torch.tensor([\n",
        "        [1000.0, 2000.0, 1200.0],  # Тестовое наблюдение 1\n",
        "        [5000.0, 1000.0, 1200.0],  # Тестовое наблюдение 2\n",
        "        [8000.0, 3000.0, 1200.0],  # Тестовое наблюдение 3\n",
        "        [2000.0, 4000.0, 1200.0],  # Тестовое наблюдение 4\n",
        "        [6000.0, 2000.0, 1200.0],  # Тестовое наблюдение 5\n",
        "    ], device=device)\n",
        "    \n",
        "    # Действия: [Kp, Ki, Kd] в диапазоне [0, 17.5], [0, 55.0], [0, 0.01]\n",
        "    fixed_actions = torch.tensor([\n",
        "        [5.0, 20.0, 0.005],  # Тестовое действие 1\n",
        "        [10.0, 30.0, 0.008], # Тестовое действие 2\n",
        "        [15.0, 40.0, 0.010], # Тестовое действие 3\n",
        "        [8.0, 25.0, 0.006],  # Тестовое действие 4\n",
        "        [12.0, 35.0, 0.009], # Тестовое действие 5\n",
        "    ], device=device)\n",
        "    \n",
        "    print(f\"Фиксированные наблюдения:\\n{fixed_observations}\")\n",
        "    print(f\"Фиксированные действия:\\n{fixed_actions}\")\n",
        "    \n",
        "    # Тестируем каждую модель на фиксированных данных\n",
        "    for exp_name, models in loaded_models.items():\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Результаты для эксперимента: {exp_name}\")\n",
        "        print(f\"{'='*50}\")\n",
        "        \n",
        "        actor = models['actor']\n",
        "        critic = models['critic']\n",
        "        \n",
        "        # Тестируем актора\n",
        "        actor_output = test_actor(actor, fixed_observations, device)\n",
        "        print(f\"Действия актора на фиксированных наблюдениях:\")\n",
        "        print(actor_output)\n",
        "        \n",
        "        # Тестируем критика с действиями от актора\n",
        "        critic_output_actor = test_critic(critic, fixed_observations, actor_output, device)\n",
        "        print(f\"Q-значения критика (действия от актора):\")\n",
        "        print(critic_output_actor)\n",
        "        \n",
        "        # Тестируем критика с фиксированными действиями\n",
        "        critic_output_fixed = test_critic(critic, fixed_observations, fixed_actions, device)\n",
        "        print(f\"Q-значения критика (фиксированные действия):\")\n",
        "        print(critic_output_fixed)\n",
        "        \n",
        "        # Сравниваем результаты\n",
        "        print(f\"\\nСравнение Q-значений:\")\n",
        "        print(f\"Среднее Q-значение (действия от актора): {critic_output_actor.mean():.4f}\")\n",
        "        print(f\"Среднее Q-значение (фиксированные действия): {critic_output_fixed.mean():.4f}\")\n",
        "        print(f\"Разность: {critic_output_actor.mean() - critic_output_fixed.mean():.4f}\")\n",
        "        \n",
        "else:\n",
        "    print(\"Нет загруженных моделей для тестирования\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Дополнительные функции для анализа\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_model_behavior(actor, critic, observation_spec, action_spec, \n",
        "                          num_samples=100, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Анализирует поведение моделей на большом количестве образцов.\n",
        "    \n",
        "    Args:\n",
        "        actor: Модель актора\n",
        "        critic: Модель критика\n",
        "        observation_spec: Спецификация наблюдений\n",
        "        action_spec: Спецификация действий\n",
        "        num_samples: Количество образцов для анализа\n",
        "        device: Устройство для вычислений\n",
        "    \n",
        "    Returns:\n",
        "        Словарь с результатами анализа\n",
        "    \"\"\"\n",
        "    print(f\"Анализ поведения моделей на {num_samples} образцах...\")\n",
        "    \n",
        "    # Генерируем тестовые данные\n",
        "    observations, random_actions = generate_test_data(observation_spec, action_spec, num_samples, device)\n",
        "    \n",
        "    # Получаем действия от актора\n",
        "    actor_actions = test_actor(actor, observations, device)\n",
        "    \n",
        "    # Получаем Q-значения\n",
        "    q_values_actor = test_critic(critic, observations, actor_actions, device)\n",
        "    q_values_random = test_critic(critic, observations, random_actions, device)\n",
        "    \n",
        "    # Анализируем поведение\n",
        "    analysis = {\n",
        "        \"actor_consistency\": actor_actions.std(dim=0).mean().item(),\n",
        "        \"actor_range\": (actor_actions.max(dim=0)[0] - actor_actions.min(dim=0)[0]).mean().item(),\n",
        "        \"q_value_advantage\": (q_values_actor.mean() - q_values_random.mean()).item(),\n",
        "        \"q_value_consistency\": q_values_actor.std().item(),\n",
        "        \"action_bounds_compliance\": (\n",
        "            (actor_actions >= action_spec.space.low).all() and \n",
        "            (actor_actions <= action_spec.space.high).all()\n",
        "        )\n",
        "    }\n",
        "    \n",
        "    print(f\"Анализ завершен:\")\n",
        "    print(f\"  Консистентность актора (среднее std): {analysis['actor_consistency']:.4f}\")\n",
        "    print(f\"  Диапазон действий актора: {analysis['actor_range']:.4f}\")\n",
        "    print(f\"  Преимущество Q-значений (актор vs случайные): {analysis['q_value_advantage']:.4f}\")\n",
        "    print(f\"  Консистентность Q-значений: {analysis['q_value_consistency']:.4f}\")\n",
        "    print(f\"  Соблюдение границ действий: {analysis['action_bounds_compliance']}\")\n",
        "    \n",
        "    return analysis\n",
        "\n",
        "# Анализируем поведение всех загруженных моделей\n",
        "if loaded_models:\n",
        "    print(\"Анализ поведения моделей:\")\n",
        "    behavior_analysis = {}\n",
        "    \n",
        "    for exp_name, models in loaded_models.items():\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Анализ эксперимента: {exp_name}\")\n",
        "        print(f\"{'='*50}\")\n",
        "        \n",
        "        actor = models['actor']\n",
        "        critic = models['critic']\n",
        "        config = models['config']\n",
        "        \n",
        "        # Получаем спецификации из конфигурации\n",
        "        specs = make_specs(config.env.bounds)\n",
        "        action_spec = specs[\"action\"]\n",
        "        observation_spec = specs[\"observation\"]\n",
        "        \n",
        "        # Анализируем поведение\n",
        "        analysis = analyze_model_behavior(actor, critic, observation_spec, action_spec, \n",
        "                                        num_samples=100, device=device)\n",
        "        behavior_analysis[exp_name] = analysis\n",
        "    \n",
        "    # Сравниваем анализ поведения\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Сравнение анализа поведения:\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    for metric in [\"actor_consistency\", \"actor_range\", \"q_value_advantage\", \"q_value_consistency\"]:\n",
        "        print(f\"\\n{metric}:\")\n",
        "        for exp_name, analysis in behavior_analysis.items():\n",
        "            print(f\"  {exp_name}: {analysis[metric]:.4f}\")\n",
        "else:\n",
        "    print(\"Нет загруженных моделей для анализа\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nn-laser-stabilizer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
