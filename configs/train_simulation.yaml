experiment_name: td3_train_simulation
seed: 42 

hydra:
  run:
    dir: experiments/${experiment_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}

data:
  frames_per_batch: 10
  total_frames: 100

  buffer_size: 50_000

agent:
  use_lstm_policy: True
  python_based_lstm_policy: False

  lstm_hidden_size: 32
  lstm_num_layers: 1

  mlp_depth: 0
  mlp_num_cells: 32

  use_lstm_qvalue: True
  python_based_lstm_qvalue: True

  q_lstm_hidden_size: 32
  q_lstm_num_layers: 1

  q_mlp_depth: 0
  q_mlp_num_cells: 32

  gamma: 0.99
  num_qvalue_nets: 2
  target_update_eps: 0.95

  learning_rate_actor: 1e-5
  learning_rate_critic: 1e-5

  exploration_sigma_init: 0.1
  exploration_sigma_end: 0.01
  exploration_annealing_steps: 1000

env:
  setpoint: 10.0
  mass: 1.0
  k_linear: 1.0
  k_nonlinear: 1.0
  k_damping: 0.1

  process_noise_std: 0.05
  measurement_noise_std: 0.02

  bounds:
    action:
      low: [0.0, 0.0, 0.0]
      high: [100.0, 100.0, 100.0]
    observation:
      low: [-inf, -inf, -inf]
      high: [inf, inf, inf]
    reward:
      low: [-inf]
      high: [inf]

train:
  batch_size: 4
  
  update_to_data: 4
  update_actor_freq: 2 

  total_train_steps: 100