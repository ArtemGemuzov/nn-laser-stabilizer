{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Анализ эксперимента с train_from_csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from nn_laser_stabilizer.config.config import load_config\n",
        "\n",
        "EXPERIMENT_DATE_TIME = \"YYYY-MM-DD_HH-MM-SS\"\n",
        "EXPERIMENT_NAME = \"train_from_csv\"\n",
        "\n",
        "EXPERIMENT_DIR_PATH = Path(f\"../experiments/{EXPERIMENT_NAME}/{EXPERIMENT_DATE_TIME}\")\n",
        "\n",
        "CONFIG_PATH = EXPERIMENT_DIR_PATH / \"config.yaml\"\n",
        "config = load_config(CONFIG_PATH)\n",
        "print(f\"Эксперимент: {config.experiment_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Анализ процесса обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def parse_train_logs(file_path):\n",
        "    step_pattern = re.compile(\n",
        "        r\"\\[TRAIN\\]\\s+\"\n",
        "        r\"step:\\s+\"\n",
        "        r\"(actor_loss=(?P<actor_loss>-?\\d+\\.\\d+)\\s+)?\"\n",
        "        r\"buffer_size=(?P<buffer_size>\\d+)\\s+\"\n",
        "        r\"loss_q1=(?P<loss_q1>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"loss_q2=(?P<loss_q2>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"step=(?P<step>\\d+)\\s+\"\n",
        "        r\"time=(?P<time>-?\\d+\\.\\d+)\"\n",
        "    )\n",
        "    \n",
        "    rows = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            match = step_pattern.match(line)\n",
        "            if match:\n",
        "                actor_loss = match.group('actor_loss')\n",
        "                rows.append({\n",
        "                    'step': int(match.group('step')),\n",
        "                    'loss_q1': float(match.group('loss_q1')),\n",
        "                    'loss_q2': float(match.group('loss_q2')),\n",
        "                    'actor_loss': float(actor_loss) if actor_loss else np.nan,\n",
        "                    'buffer_size': int(match.group('buffer_size'))\n",
        "                })\n",
        "    \n",
        "    return pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_LOG_PATH = EXPERIMENT_DIR_PATH / \"train_logs\" / \"train.log\"\n",
        "loss_df = parse_train_logs(TRAIN_LOG_PATH)\n",
        "print(f\"Загружено {len(loss_df)} записей из логов обучения\")\n",
        "print(f\"Диапазон шагов обучения: {loss_df['step'].min()} - {loss_df['step'].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
        "\n",
        "axes[0].plot(loss_df['step'], loss_df['loss_q1'], 'b-', alpha=0.7, label='Q1 Loss')\n",
        "axes[0].set_title('Q1 Loss')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(loss_df['step'], loss_df['loss_q2'], 'g-', alpha=0.7, label='Q2 Loss')\n",
        "axes[1].set_title('Q2 Loss')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].plot(loss_df['step'], loss_df['loss_q1'] + loss_df['loss_q2'], 'r--', alpha=0.7, label='Sum (Q1 + Q2)')\n",
        "axes[2].set_title('Sum (Q1 + Q2)')\n",
        "axes[2].set_xlabel('Step')\n",
        "axes[2].set_ylabel('Loss')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "actor_loss_df = loss_df[loss_df['actor_loss'].notna()]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.plot(actor_loss_df['step'], actor_loss_df['actor_loss'], 'r-', alpha=0.7)\n",
        "plt.title('Actor Loss')\n",
        "\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(loss_df['step'], loss_df['buffer_size'], 'm-', alpha=0.7)\n",
        "plt.title('Buffer Size')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Size')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nn-laser-stabilizer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
