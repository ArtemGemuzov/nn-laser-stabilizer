{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Анализ ДВУХ экспериментов по подстройке коэффициентов Kp, Ki, Kd от 02 и 04 декабря 2025\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from pathlib import Path\n",
        "from nn_laser_stabilizer.config import load_config\n",
        "\n",
        "EXPERIMENT_DIR = Path(\"../experiments/pid_delta_tuning/2025-12-02_12-50-33\")\n",
        "# EXPERIMENT_DIR = Path(\"../experiments/pid_delta_tuning/2025-12-04_16-12-21\")\n",
        "# EXPERIMENT_DIR = Path(\"../experiments/pid_delta_tuning/2025-12-04_17-21-28\")\n",
        "\n",
        "CONFIG_PATH = EXPERIMENT_DIR / \"config.yaml\"\n",
        "ENV_LOG_PATH = EXPERIMENT_DIR / \"env_logs\" / \"env.log\"\n",
        "TRAIN_LOG_PATH = EXPERIMENT_DIR / \"train_logs\" / \"train.log\"\n",
        "CONNECTION_LOG_PATH = EXPERIMENT_DIR / \"connection_logs\" / \"connection.log\"\n",
        "\n",
        "config = load_config(CONFIG_PATH)\n",
        "print(f\"Эксперимент: {config.experiment_name}\")\n",
        "print(f\"Seed: {config.seed}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В эксперименте от 02 декабря нет поля `delta_kd_norm`, поэтому эти ячейки нужно закомментировать."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Анализ логов окружения\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_env_logs(file_path):\n",
        "    step_pattern = re.compile(\n",
        "        r\"step=(?P<step>\\d+)\\s+\"\n",
        "        r\"time=(?P<time>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kp=(?P<kp>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"ki=(?P<ki>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kd=(?P<kd>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"delta_kp_norm=(?P<delta_kp_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"delta_ki_norm=(?P<delta_ki_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        # r\"delta_kd_norm=(?P<delta_kd_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_mean_norm=(?P<error_mean_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_std_norm=(?P<error_std_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"reward=(?P<reward>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"should_reset=(?P<should_reset>\\w+)\"\n",
        "    )\n",
        "    \n",
        "    reset_pattern = re.compile(\n",
        "        r\"reset\\s+time=(?P<time>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kp=(?P<kp>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"ki=(?P<ki>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kd=(?P<kd>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_mean_norm=(?P<error_mean_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_std_norm=(?P<error_std_norm>-?\\d+\\.\\d+)\"\n",
        "    )\n",
        "    \n",
        "    rows = []\n",
        "    reset_steps = []\n",
        "    current_step = 0\n",
        "    \n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            \n",
        "            reset_match = reset_pattern.match(line)\n",
        "            if reset_match:\n",
        "                reset_steps.append(current_step)\n",
        "                rows.append({\n",
        "                    'Step': current_step,\n",
        "                    'time': float(reset_match.group('time')),\n",
        "                    'Type': 'reset',\n",
        "                    'Kp': float(reset_match.group('kp')),\n",
        "                    'Ki': float(reset_match.group('ki')),\n",
        "                    'Kd': float(reset_match.group('kd')),\n",
        "                    'Delta Kp': np.nan,\n",
        "                    'Delta Ki': np.nan,\n",
        "                    # 'Delta Kd': np.nan,\n",
        "                    'Error mean norm': float(reset_match.group('error_mean_norm')),\n",
        "                    'Error std norm': float(reset_match.group('error_std_norm')),\n",
        "                    'Reward': np.nan,\n",
        "                    'Should reset': True\n",
        "                })\n",
        "                continue\n",
        "            \n",
        "            step_match = step_pattern.match(line)\n",
        "            if step_match:\n",
        "                current_step = int(step_match.group('step'))\n",
        "                should_reset = step_match.group('should_reset').lower() == 'true'\n",
        "                \n",
        "                rows.append({\n",
        "                    'Step': current_step,\n",
        "                    'time': float(step_match.group('time')),\n",
        "                    'Type': 'step',\n",
        "                    'Kp': float(step_match.group('kp')),\n",
        "                    'Ki': float(step_match.group('ki')),\n",
        "                    'Kd': float(step_match.group('kd')),\n",
        "                    'Delta Kp': float(step_match.group('delta_kp_norm')),\n",
        "                    'Delta Ki': float(step_match.group('delta_ki_norm')),\n",
        "                    # 'Delta Kd': float(step_match.group('delta_kd_norm')),\n",
        "                    'Error mean norm': float(step_match.group('error_mean_norm')),\n",
        "                    'Error std norm': float(step_match.group('error_std_norm')),\n",
        "                    'Reward': float(step_match.group('reward')),\n",
        "                    'Should reset': should_reset\n",
        "                })\n",
        "    \n",
        "    return pd.DataFrame(rows), reset_steps\n",
        "\n",
        "env_df, reset_steps = parse_env_logs(ENV_LOG_PATH)\n",
        "print(f\"Загружено {len(env_df)} записей из логов окружения\")\n",
        "print(f\"Найдено {len(reset_steps)} reset событий\")\n",
        "print(f\"Диапазон шагов: {env_df['Step'].min()} - {env_df['Step'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "step_df = env_df[env_df['Type'] == 'step'].copy()\n",
        "print(\"=== Статистика по шагам окружения ===\")\n",
        "print(step_df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exploration_steps = config.training.exploration_steps\n",
        "initial_collect_steps = config.training.initial_collect_steps\n",
        "neural_network_step = max(initial_collect_steps, exploration_steps) - 100 # этап warmup\n",
        "\n",
        "columns_to_plot = ['Error mean norm', 'Error std norm', 'Reward']\n",
        "\n",
        "for col in columns_to_plot:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(step_df['Step'], step_df[col], alpha=0.8, linewidth=0.8, label=col)\n",
        "    \n",
        "    for reset_step in reset_steps:\n",
        "        if reset_step <= step_df['Step'].max():\n",
        "            plt.axvline(x=reset_step, color='orange', linestyle=':', linewidth=2, alpha=0.6)\n",
        "    \n",
        "    if neural_network_step <= step_df['Step'].max():\n",
        "        plt.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2, \n",
        "                    label=f'Switch to NN (step {neural_network_step})')\n",
        "    \n",
        "    plt.title(f'{col} over Steps')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel(col)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = ['Kp', 'Ki', 'Kd']\n",
        "fig, axes = plt.subplots(len(cols), 1, figsize=(14, 10), sharex=True)\n",
        "\n",
        "for ax, col in zip(axes, cols):\n",
        "    ax.plot(step_df['Step'], step_df[col], alpha=0.8, linewidth=0.8, label=col)\n",
        "\n",
        "    for reset_step in reset_steps:\n",
        "        if reset_step <= step_df['Step'].max():\n",
        "            ax.axvline(x=reset_step, color='orange', linestyle=':', linewidth=2, alpha=0.6)\n",
        "\n",
        "    if neural_network_step <= step_df['Step'].max():\n",
        "        ax.axvline(\n",
        "            x=neural_network_step,\n",
        "            color='red',\n",
        "            linestyle='--',\n",
        "            linewidth=2,\n",
        "            label=f'Switch NN ({neural_network_step})'\n",
        "        )\n",
        "\n",
        "    ax.set_ylabel(col)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "\n",
        "axes[-1].set_xlabel(\"Step\")\n",
        "plt.suptitle(\"Kp / Ki / Kd over Steps\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.savefig('pid_coeffs_vs_block_step.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Анализ процесса обучения\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_train_logs(file_path):\n",
        "    pattern = re.compile(\n",
        "        r\"step=(?P<step>\\d+)\\s+\"\n",
        "        r\"time=(?P<time>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"loss_q1=(?P<loss_q1>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"loss_q2=(?P<loss_q2>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"(actor_loss=(?P<actor_loss>-?\\d+\\.\\d+)\\s+)?\"\n",
        "        r\"buffer_size=(?P<buffer_size>\\d+)\"\n",
        "    )\n",
        "    \n",
        "    rows = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            match = pattern.match(line)\n",
        "            if match:\n",
        "                actor_loss = match.group('actor_loss')\n",
        "                rows.append({\n",
        "                    'step': int(match.group('step')),\n",
        "                    'loss_q1': float(match.group('loss_q1')),\n",
        "                    'loss_q2': float(match.group('loss_q2')),\n",
        "                    'actor_loss': float(actor_loss) if actor_loss else np.nan,\n",
        "                    'buffer_size': int(match.group('buffer_size'))\n",
        "                })\n",
        "    \n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "loss_df = parse_train_logs(TRAIN_LOG_PATH)\n",
        "print(f\"Загружено {len(loss_df)} записей из логов обучения\")\n",
        "print(f\"Диапазон шагов обучения: {loss_df['step'].min()} - {loss_df['step'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
        "\n",
        "axes[0].plot(loss_df['step'], loss_df['loss_q1'], 'b-', alpha=0.7, label='Q1 Loss')\n",
        "axes[0].set_title('Q1 Loss')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(loss_df['step'], loss_df['loss_q2'], 'g-', alpha=0.7, label='Q2 Loss')\n",
        "axes[1].set_title('Q2 Loss')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].plot(loss_df['step'], loss_df['loss_q1'] + loss_df['loss_q2'], 'r--', alpha=0.7, label='Sum (Q1 + Q2)')\n",
        "axes[2].set_title('Sum (Q1 + Q2)')\n",
        "axes[2].set_xlabel('Step')\n",
        "axes[2].set_ylabel('Loss')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('critics_loss.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "actor_loss_df = loss_df[loss_df['actor_loss'].notna()]\n",
        "if len(actor_loss_df) > 0:\n",
        "    plt.plot(actor_loss_df['step'], actor_loss_df['actor_loss'], 'r-', alpha=0.7)\n",
        "    plt.title('Actor Loss')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'No actor loss data', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Actor Loss (no data)')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('actor_loss.png')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(loss_df['step'], loss_df['buffer_size'], 'm-', alpha=0.7)\n",
        "plt.title('Buffer Size')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Size')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Анализ состояния установки\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_size = config.env.args.block_size\n",
        "for i in range(1, len(reset_steps)):\n",
        "    reset_steps[i] = reset_steps[i] * block_size + 1000  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_connection_logs(file_path):\n",
        "    send_pattern = re.compile(r\"SEND: kp=(?P<kp>-?\\d+\\.\\d+) ki=(?P<ki>-?\\d+\\.\\d+) kd=(?P<kd>-?\\d+\\.\\d+) control_min=(?P<control_min>\\d+) control_max=(?P<control_max>\\d+)\")\n",
        "    read_pattern = re.compile(r\"READ: process_variable=(?P<process_variable>-?\\d+\\.\\d+) control_output=(?P<control_output>-?\\d+\\.\\d+)\")\n",
        "    \n",
        "    send_rows = []\n",
        "    read_rows = []\n",
        "    step = 0\n",
        "    \n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            \n",
        "            send_match = send_pattern.match(line)\n",
        "            if send_match:\n",
        "                send_rows.append({\n",
        "                    'step': step,\n",
        "                    'type': 'SEND',\n",
        "                    'kp': float(send_match.group('kp')),\n",
        "                    'ki': float(send_match.group('ki')),\n",
        "                    'kd': float(send_match.group('kd')),\n",
        "                    'control_min': int(send_match.group('control_min')),\n",
        "                    'control_max': int(send_match.group('control_max'))\n",
        "                })\n",
        "                step += 1\n",
        "            \n",
        "            read_match = read_pattern.match(line)\n",
        "            if read_match:\n",
        "                read_rows.append({\n",
        "                    'step': step - 1,\n",
        "                    'type': 'READ',\n",
        "                    'process_variable': float(read_match.group('process_variable')),\n",
        "                    'control_output': float(read_match.group('control_output'))\n",
        "                })\n",
        "    \n",
        "    connection_df = pd.DataFrame(send_rows)\n",
        "    read_df = pd.DataFrame(read_rows)\n",
        "    \n",
        "    if not connection_df.empty and not read_df.empty:\n",
        "        connection_df = connection_df.merge(read_df[['step', 'process_variable', 'control_output']], \n",
        "                                          on='step', how='left')\n",
        "    \n",
        "    return connection_df\n",
        "\n",
        "connection_df = parse_connection_logs(CONNECTION_LOG_PATH)\n",
        "print(f\"Загружено {len(connection_df)} записей из логов соединения\")\n",
        "if len(connection_df) > 0:\n",
        "    print(f\"Диапазон шагов: {connection_df['step'].min()} - {connection_df['step'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neural_network_step = neural_network_step * config.env.args.block_size + len(reset_steps) * 1000\n",
        "if len(connection_df) > 0:\n",
        "    setpoint = config.env.args.setpoint\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(connection_df['step'], connection_df['process_variable'], 'b-', alpha=0.7, linewidth=0.8, label='Process Variable')\n",
        "    plt.axhline(y=setpoint, color='r', linestyle='--', label=f'Setpoint ({setpoint})')\n",
        "    \n",
        "    for reset_step in reset_steps:\n",
        "        if reset_step <= connection_df['step'].max():\n",
        "            plt.axvline(x=reset_step, color='orange', linestyle=':', linewidth=2, alpha=0.6)\n",
        "    \n",
        "    if neural_network_step <= connection_df['step'].max():\n",
        "        plt.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2, \n",
        "                    label=f'Switch to NN (step {neural_network_step})')\n",
        "    \n",
        "    plt.title('Process Variable')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylim(500, 1700)\n",
        "    plt.ylabel('Process Variable')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('process_variable_over_connection_steps.png')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(connection_df['step'], connection_df['control_output'], 'g-', alpha=0.7, linewidth=0.8, label='Control Output')\n",
        "    \n",
        "    for reset_step in reset_steps:\n",
        "        if reset_step <= connection_df['step'].max():\n",
        "            plt.axvline(x=reset_step, color='orange', linestyle=':', linewidth=2, alpha=0.6)\n",
        "    \n",
        "    if neural_network_step <= connection_df['step'].max():\n",
        "        plt.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2, \n",
        "                    label=f'Switch to NN (step {neural_network_step})')\n",
        "    \n",
        "    plt.title('Control Output')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Control Output')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('control_output_over_connection_steps.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env_df = env_df.sort_values('time').copy()\n",
        "\n",
        "env_df['time_diff'] = env_df['time'].diff()\n",
        "env_df['time_diff_ms'] = env_df['time_diff'] * 1000  \n",
        "\n",
        "step_time_df = env_df[env_df['Type'] == 'step'].copy()\n",
        "time_df = env_df.copy()\n",
        "\n",
        "print(\"=== Статистика по времени ===\")\n",
        "print(f\"Всего записей: {len(time_df)}\")\n",
        "print(f\"Шагов: {len(time_df[time_df['Type'] == 'step'])}\")\n",
        "print(f\"Reset событий: {len(time_df[time_df['Type'] == 'reset'])}\")\n",
        "\n",
        "if len(step_time_df) > 0:\n",
        "    print(f\"\\n=== Статистика интервалов между шагами ===\")\n",
        "    print(step_time_df['time_diff_ms'].describe())\n",
        "    print(f\"\\nМедианный интервал: {step_time_df['time_diff_ms'].median():.2f} мс\")\n",
        "    print(f\"Средний интервал: {step_time_df['time_diff_ms'].mean():.2f} мс\")\n",
        "    print(f\"Максимальный интервал: {step_time_df['time_diff_ms'].max():.2f} мс\")\n",
        "    print(f\"Минимальный интервал: {step_time_df['time_diff_ms'].min():.2f} мс\")\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(step_time_df['Step'], step_time_df['time_diff_ms'], 'b-', alpha=0.7, linewidth=0.8)\n",
        "    plt.title('Time Intervals Between Steps')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Time Interval (ms)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.hist(step_time_df['time_diff_ms'].dropna(), bins=50, alpha=0.7, edgecolor='black')\n",
        "    plt.title('Distribution of Time Intervals Between Steps')\n",
        "    plt.xlabel('Time Interval (ms)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reset_time_df = env_df[env_df['Type'] == 'reset'].copy()\n",
        "if len(reset_time_df) > 0:\n",
        "    print(f\"\\n=== Статистика интервалов между шагами ===\")\n",
        "    print(reset_time_df['time_diff_ms'].describe())\n",
        "    print(f\"\\nМедианный интервал: {reset_time_df['time_diff_ms'].median():.2f} мс\")\n",
        "    print(f\"Средний интервал: {reset_time_df['time_diff_ms'].mean():.2f} мс\")\n",
        "    print(f\"Максимальный интервал: {reset_time_df['time_diff_ms'].max():.2f} мс\")\n",
        "    print(f\"Минимальный интервал: {reset_time_df['time_diff_ms'].min():.2f} мс\")\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(reset_time_df['Step'], reset_time_df['time_diff_ms'], 'b-', alpha=0.7, linewidth=0.8)\n",
        "    plt.title('Time Intervals Between Steps')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Time Interval (ms)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.hist(reset_time_df['time_diff_ms'].dropna(), bins=50, alpha=0.7, edgecolor='black')\n",
        "    plt.title('Distribution of Time Intervals Between Steps')\n",
        "    plt.xlabel('Time Interval (ms)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Графики для встречи 26 декабря 2025 г."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neural_network_step = max(initial_collect_steps, exploration_steps) - 100 # этап warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "plt.rcParams.update({'font.size': 14})  \n",
        "\n",
        "columns_left = ['Kp', 'Ki', 'Kd']\n",
        "colors_left = ['green', 'blue', 'orange']  \n",
        "column_right = 'Error std norm'\n",
        "\n",
        "fig = plt.figure(figsize=(16, 6))\n",
        "gs = GridSpec(3, 2, width_ratios=[1, 1.2], height_ratios=[1,1,1], wspace=0.3, hspace=0.4)\n",
        "\n",
        "for i, col in enumerate(columns_left):\n",
        "    ax = fig.add_subplot(gs[i,0])\n",
        "    ax.plot(step_df['Step'], step_df[col], alpha=0.8, linewidth=1.2, color=colors_left[i])\n",
        "    \n",
        "    if neural_network_step <= step_df['Step'].max():\n",
        "        ax.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2)\n",
        "    \n",
        "    ax.set_ylabel(col)\n",
        "    ax.set_xlabel('Block')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax_right = fig.add_subplot(gs[:,1])  \n",
        "ax_right.plot(step_df['Step'], step_df[column_right], alpha=0.8, linewidth=1.5, color='purple', label=column_right)\n",
        "\n",
        "if neural_network_step <= step_df['Step'].max():\n",
        "    ax_right.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2, label='Switch to NN')\n",
        "\n",
        "ax_right.set_xlabel('Block')\n",
        "ax_right.set_ylabel(column_right)\n",
        "ax_right.grid(True, alpha=0.3)\n",
        "ax_right.legend()\n",
        "\n",
        "fig.subplots_adjust(left=0.08, right=0.95, top=0.93, bottom=0.08, wspace=0.3, hspace=0.4)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "neural_network_step = neural_network_step * config.env.args.block_size + len(reset_steps) * 1000\n",
        "\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "columns_left = ['process_variable']\n",
        "columns_right = ['control_output']\n",
        "fig = plt.figure(figsize=(18, 6))\n",
        "gs = GridSpec(1, 2, width_ratios=[1, 1], wspace=0.3)\n",
        "\n",
        "ax_left = fig.add_subplot(gs[0,0])\n",
        "ax_left.plot(connection_df['step'], connection_df['process_variable'], 'b-', alpha=0.7, linewidth=1.2, label='Process Variable')\n",
        "ax_left.axhline(y=setpoint, color='r', linestyle='--', label=f'Setpoint')\n",
        "ax_left.set_xlim(left=100)\n",
        "\n",
        "if neural_network_step <= connection_df['step'].max():\n",
        "    ax_left.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2, label='Switch to NN')\n",
        "\n",
        "ax_left.set_xlabel('Step')\n",
        "ax_left.set_ylabel('Process Variable')\n",
        "ax_left.set_title('Process Variable')\n",
        "ax_left.grid(True, alpha=0.3)\n",
        "ax_left.legend()\n",
        "\n",
        "ax_right = fig.add_subplot(gs[0,1])\n",
        "ax_right.plot(connection_df['step'], connection_df['control_output'], 'g-', alpha=0.7, linewidth=1.2, label='Control Output')\n",
        "ax_right.set_xlim(left=100)\n",
        "\n",
        "if neural_network_step <= connection_df['step'].max():\n",
        "    ax_right.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2)\n",
        "\n",
        "ax_right.set_xlabel('Step')\n",
        "ax_right.set_ylabel('Control Output')\n",
        "ax_right.set_title('Control Output')\n",
        "ax_right.grid(True, alpha=0.3)\n",
        "ax_right.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.plot(connection_df['step'], connection_df['control_output'], 'g-', alpha=0.7, linewidth=1.2, label='Control Output')\n",
        "\n",
        "if neural_network_step <= connection_df['step'].max():\n",
        "    plt.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2, label='Switch to NN')\n",
        "\n",
        "plt.xlim(left=100)\n",
        "\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Control Output')\n",
        "plt.title('Control Output')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "actor_loss_df = loss_df[loss_df['actor_loss'].notna()]\n",
        "if len(actor_loss_df) > 0:\n",
        "    plt.plot(actor_loss_df['step'], actor_loss_df['actor_loss'], 'r-', alpha=0.7)\n",
        "    plt.title('Actor Loss (Kp, Ki, Kd)')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'No actor loss data', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Actor Loss (no data)')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nn-laser-stabilizer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
