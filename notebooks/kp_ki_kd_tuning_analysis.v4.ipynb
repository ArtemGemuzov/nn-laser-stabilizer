{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Анализ эксперимента по подстройке коэффициентов Kp, Ki, Kd с включенной термостабилизацией и другим setpoint от 17 и 19 января 2026 г\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from nn_laser_stabilizer.experiment.config import load_config\n",
        "\n",
        "EXPERIMENT_DIR = \"pid_delta_tuning/2026-01-19_16-49-40\"\n",
        "EXPERIMENT_DIR_PATH = Path(f\"../experiments/{EXPERIMENT_DIR}\")\n",
        "\n",
        "ENV_LOG_PATH = EXPERIMENT_DIR_PATH / \"env_logs\" / \"env.log\"\n",
        "TRAIN_LOG_PATH = EXPERIMENT_DIR_PATH / \"train_logs\" / \"train.log\"\n",
        "\n",
        "CONFIG_PATH = EXPERIMENT_DIR_PATH / \"config.yaml\"\n",
        "config = load_config(CONFIG_PATH)\n",
        "print(f\"Эксперимент: {config.experiment_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Анализ логов окружения\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def parse_env_logs(file_path: str | Path) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    step_pattern = re.compile(\n",
        "        r\"\\[ENV\\]\\s+\"\n",
        "        r\"step:\\s+\"\n",
        "        r\"step=(?P<step>\\d+)\\s+\"\n",
        "        r\"time=(?P<time>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kp=(?P<kp>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"ki=(?P<ki>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kd=(?P<kd>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"delta_kp_norm=(?P<delta_kp_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"delta_ki_norm=(?P<delta_ki_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"delta_kd_norm=(?P<delta_kd_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_mean_norm=(?P<error_mean_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_std_norm=(?P<error_std_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"reward=(?P<reward>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"should_reset=(?P<should_reset>\\w+)\"\n",
        "    )\n",
        "    \n",
        "    reset_pattern = re.compile(\n",
        "        r\"\\[ENV\\]\\s+\"\n",
        "        r\"reset:\\s+\"\n",
        "        r\"time=(?P<time>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kp=(?P<kp>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"ki=(?P<ki>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kd=(?P<kd>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_mean_norm=(?P<error_mean_norm>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"error_std_norm=(?P<error_std_norm>-?\\d+\\.\\d+)\"\n",
        "    )\n",
        "    \n",
        "    pid_send_pattern = re.compile(\n",
        "        r\"\\[PID\\]\\s+\"\n",
        "        r\"send:\\s+\"\n",
        "        r\"kp=(?P<kp>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"ki=(?P<ki>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"kd=(?P<kd>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"control_min=(?P<control_min>\\d+)\\s+\"\n",
        "        r\"control_max=(?P<control_max>\\d+)\\s+\"\n",
        "        r\"setpoint=(?P<setpoint>\\d+)\"\n",
        "    )\n",
        "    \n",
        "    pid_read_pattern = re.compile(\n",
        "        r\"\\[PID\\]\\s+\"\n",
        "        r\"read:\\s+\"\n",
        "        r\"process_variable=(?P<process_variable>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"control_output=(?P<control_output>-?\\d+\\.\\d+)\"\n",
        "    )\n",
        "    \n",
        "    env_rows = []\n",
        "    conn_rows = []\n",
        "    current_step = 0\n",
        "    connection_step = 0\n",
        "    \n",
        "    pending_send = None\n",
        "    line_number = 0  \n",
        "    \n",
        "    with open(file_path, 'r') as f:\n",
        "        for raw_line in f:\n",
        "            line_number += 1\n",
        "            line = raw_line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            m = pid_send_pattern.match(line)\n",
        "            if m:\n",
        "                pending_send = {\n",
        "                    'kp': float(m.group('kp')),\n",
        "                    'ki': float(m.group('ki')),\n",
        "                    'kd': float(m.group('kd')),\n",
        "                    'control_min': int(m.group('control_min')),\n",
        "                    'control_max': int(m.group('control_max')),\n",
        "                    'setpoint': int(m.group('setpoint')),\n",
        "                    'line': line_number,\n",
        "                }\n",
        "                continue\n",
        "            \n",
        "            m = pid_read_pattern.match(line)\n",
        "            if m:\n",
        "                if pending_send is None:\n",
        "                    raise ValueError(\n",
        "                        f\"PID READ without matching SEND at line {line_number}: {raw_line!r}\"\n",
        "                    )\n",
        "                \n",
        "                conn_rows.append({\n",
        "                    'Connection step': connection_step,\n",
        "                    'Type': 'exchange',\n",
        "                    'Kp': pending_send['kp'],\n",
        "                    'Ki': pending_send['ki'],\n",
        "                    'Kd': pending_send['kd'],\n",
        "                    'Control min': pending_send['control_min'],\n",
        "                    'Control max': pending_send['control_max'],\n",
        "                    'Process variable': float(m.group('process_variable')),\n",
        "                    'Control output': float(m.group('control_output')),\n",
        "                    'Setpoint': pending_send['setpoint']\n",
        "                })\n",
        "                connection_step += 1\n",
        "                continue\n",
        "             \n",
        "            m = reset_pattern.match(line)\n",
        "            if m:\n",
        "                env_rows.append({\n",
        "                    'Step': current_step,\n",
        "                    'time': float(m.group('time')),\n",
        "                    'Type': 'reset',\n",
        "                    'Kp': float(m.group('kp')),\n",
        "                    'Ki': float(m.group('ki')),\n",
        "                    'Kd': float(m.group('kd')),\n",
        "                    'Delta Kp': np.nan,\n",
        "                    'Delta Ki': np.nan,\n",
        "                    'Delta Kd': np.nan,\n",
        "                    'Error mean norm': float(m.group('error_mean_norm')),\n",
        "                    'Error std norm': float(m.group('error_std_norm')),\n",
        "                    'Reward': np.nan,\n",
        "                    'Should reset': True,\n",
        "                })\n",
        "                continue\n",
        "            \n",
        "            m = step_pattern.match(line)\n",
        "            if m:\n",
        "                current_step = int(m.group('step'))\n",
        "                env_rows.append({\n",
        "                    'Step': current_step,\n",
        "                    'time': float(m.group('time')),\n",
        "                    'Type': 'step',\n",
        "                    'Kp': float(m.group('kp')),\n",
        "                    'Ki': float(m.group('ki')),\n",
        "                    'Kd': float(m.group('kd')),\n",
        "                    'Delta Kp': float(m.group('delta_kp_norm')),\n",
        "                    'Delta Ki': float(m.group('delta_ki_norm')),\n",
        "                    'Delta Kd': float(m.group('delta_kd_norm')),\n",
        "                    'Error mean norm': float(m.group('error_mean_norm')),\n",
        "                    'Error std norm': float(m.group('error_std_norm')),\n",
        "                    'Reward': float(m.group('reward')),\n",
        "                    'Should reset': m.group('should_reset').lower() == 'true',\n",
        "                })\n",
        "                continue\n",
        "    \n",
        "    env_df = pd.DataFrame(env_rows)\n",
        "    connection_df = pd.DataFrame(conn_rows)\n",
        "    return env_df, connection_df\n",
        "\n",
        "env_df, connection_df = parse_env_logs(ENV_LOG_PATH)\n",
        "print(f\"Загружено {len(env_df)} записей из логов окружения\")\n",
        "print(f\"Загружено {len(connection_df)} записей из логов соединения\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "step_df = env_df[env_df['Type'] == 'step'].copy()\n",
        "print(\"=== Статистика по шагам окружения ===\")\n",
        "print(step_df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exploration_steps = config.training.exploration_steps\n",
        "initial_collect_steps = config.training.initial_collect_steps\n",
        "neural_network_step = max(initial_collect_steps, exploration_steps)\n",
        "\n",
        "columns_to_plot = ['Error mean norm', 'Error std norm', 'Reward']\n",
        "\n",
        "for col in columns_to_plot:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(step_df['Step'], step_df[col], alpha=0.8, linewidth=0.8, label=col)\n",
        "    \n",
        "    if neural_network_step <= step_df['Step'].max():\n",
        "        plt.axvline(x=neural_network_step, color='red', linestyle='--', linewidth=2, \n",
        "                    label=f'Switch to NN (step {neural_network_step})')\n",
        "    \n",
        "    plt.title(f'{col} over Steps')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel(col)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision_weight = config.env.args.precision_weight\n",
        "stability_weight = config.env.args.action_weight\n",
        "action_weight = config.env.args.stability_weight\n",
        "\n",
        "step_df['precision_penalty'] = precision_weight * -step_df['Error mean norm'].abs()\n",
        "step_df['stability_penalty'] = stability_weight * -step_df['Error std norm'].abs()\n",
        "step_df['action_penalty'] = action_weight * -(\n",
        "    step_df['Delta Kp'].abs() + \n",
        "    step_df['Delta Ki'].abs() + \n",
        "    step_df['Delta Kd'].abs()\n",
        ") / 3.0\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
        "\n",
        "ax1 = axes[0]\n",
        "ax1.plot(step_df['Step'], step_df['precision_penalty'], 'b-', alpha=0.7, linewidth=0.8, label='Precision penalty (mean)')\n",
        "ax1.plot(step_df['Step'], step_df['stability_penalty'], 'r-', alpha=0.7, linewidth=0.8, label='Stability penalty (std)')\n",
        "ax1.plot(step_df['Step'], step_df['action_penalty'], 'g-', alpha=0.7, linewidth=0.8, label='Action penalty')\n",
        "ax1.set_ylabel('Penalty Value', fontsize=12)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend(loc='best')\n",
        "\n",
        "ax2 = axes[1]\n",
        "ax2.plot(step_df['Step'], step_df['Reward'], 'm-', alpha=0.8, linewidth=1.0, label='Total Reward')\n",
        "ax2.set_xlabel('Step', fontsize=12)\n",
        "ax2.set_ylabel('Reward', fontsize=12)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend(loc='best')\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = ['Kp', 'Ki', 'Kd']\n",
        "fig, axes = plt.subplots(len(cols), 1, figsize=(14, 10), sharex=True)\n",
        "\n",
        "for ax, col in zip(axes, cols):\n",
        "    ax.plot(step_df['Step'], step_df[col], alpha=0.8, linewidth=0.8, label=col)\n",
        "\n",
        "    if neural_network_step <= step_df['Step'].max():\n",
        "        ax.axvline(\n",
        "            x=neural_network_step,\n",
        "            color='red',\n",
        "            linestyle='--',\n",
        "            linewidth=2,\n",
        "            label=f'Switch NN ({neural_network_step})'\n",
        "        )\n",
        "\n",
        "    ax.set_ylabel(col)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "\n",
        "axes[-1].set_xlabel(\"Step\")\n",
        "plt.suptitle(\"Kp / Ki / Kd over Steps\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Анализ состояния установки\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В одном эксперимент есть выброс process variable, который надо отбросить."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# connection_df = connection_df.drop(connection_df['Process variable'].idxmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_size = config.env.args.block_size\n",
        "\n",
        "neural_network_connection_step = neural_network_step * block_size\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(connection_df['Connection step'], connection_df['Process variable'], 'b-', alpha=0.7, linewidth=0.8, label='Process Variable')\n",
        "plt.plot(connection_df['Connection step'], connection_df['Setpoint'], color='r', linestyle='--')\n",
        "\n",
        "if neural_network_connection_step <= connection_df['Connection step'].max():\n",
        "    plt.axvline(x=neural_network_connection_step, color='red', linestyle='--', linewidth=2, \n",
        "                label=f'Switch to NN (step {neural_network_connection_step})')\n",
        "\n",
        "plt.title('Process Variable')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Process Variable')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(connection_df['Connection step'], connection_df['Control output'], 'g-', alpha=0.7, linewidth=0.8, label='Control Output')\n",
        "\n",
        "if neural_network_connection_step <= connection_df['Connection step'].max():\n",
        "    plt.axvline(x=neural_network_connection_step, color='red', linestyle='--', linewidth=2, \n",
        "                label=f'Switch to NN (step {neural_network_connection_step})')\n",
        "\n",
        "plt.title('Control Output')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Control Output')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env_df = env_df.sort_values('time').copy()\n",
        "\n",
        "env_df['time_diff'] = env_df['time'].diff()\n",
        "env_df['time_diff_ms'] = env_df['time_diff'] * 1000  \n",
        "\n",
        "step_time_df = env_df[env_df['Type'] == 'step'].copy()\n",
        "time_df = env_df.copy()\n",
        "\n",
        "print(\"=== Статистика по времени ===\")\n",
        "print(f\"Всего записей: {len(time_df)}\")\n",
        "print(f\"Шагов: {len(time_df[time_df['Type'] == 'step'])}\")\n",
        "print(f\"Reset событий: {len(time_df[time_df['Type'] == 'reset'])}\")\n",
        "\n",
        "if len(step_time_df) > 0:\n",
        "    print(f\"\\n=== Статистика интервалов между шагами ===\")\n",
        "    print(step_time_df['time_diff_ms'].describe())\n",
        "    print(f\"\\nМедианный интервал: {step_time_df['time_diff_ms'].median():.2f} мс\")\n",
        "    print(f\"Средний интервал: {step_time_df['time_diff_ms'].mean():.2f} мс\")\n",
        "    print(f\"Максимальный интервал: {step_time_df['time_diff_ms'].max():.2f} мс\")\n",
        "    print(f\"Минимальный интервал: {step_time_df['time_diff_ms'].min():.2f} мс\")\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.plot(step_time_df['Step'], step_time_df['time_diff_ms'], 'b-', alpha=0.7, linewidth=0.8)\n",
        "    plt.title('Time Intervals Between Steps')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Time Interval (ms)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.hist(step_time_df['time_diff_ms'].dropna(), bins=50, alpha=0.7, edgecolor='black')\n",
        "    plt.title('Distribution of Time Intervals Between Steps')\n",
        "    plt.xlabel('Time Interval (ms)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Анализ процесса обучения\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_train_logs(file_path):\n",
        "    step_pattern = re.compile(\n",
        "        r\"\\[TRAIN\\]\\s+\"\n",
        "        r\"step:\\s+\"\n",
        "        r\"(actor_loss=(?P<actor_loss>-?\\d+\\.\\d+)\\s+)?\"\n",
        "        r\"buffer_size=(?P<buffer_size>\\d+)\\s+\"\n",
        "        r\"loss_q1=(?P<loss_q1>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"loss_q2=(?P<loss_q2>-?\\d+\\.\\d+)\\s+\"\n",
        "        r\"step=(?P<step>\\d+)\\s+\"\n",
        "        r\"time=(?P<time>-?\\d+\\.\\d+)\"\n",
        "    )\n",
        "    \n",
        "    rows = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            match = step_pattern.match(line)\n",
        "            if match:\n",
        "                actor_loss = match.group('actor_loss')\n",
        "                rows.append({\n",
        "                    'step': int(match.group('step')),\n",
        "                    'loss_q1': float(match.group('loss_q1')),\n",
        "                    'loss_q2': float(match.group('loss_q2')),\n",
        "                    'actor_loss': float(actor_loss) if actor_loss else np.nan,\n",
        "                    'buffer_size': int(match.group('buffer_size'))\n",
        "                })\n",
        "    \n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "loss_df = parse_train_logs(TRAIN_LOG_PATH)\n",
        "print(f\"Загружено {len(loss_df)} записей из логов обучения\")\n",
        "print(f\"Диапазон шагов обучения: {loss_df['step'].min()} - {loss_df['step'].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
        "\n",
        "axes[0].plot(loss_df['step'], loss_df['loss_q1'], 'b-', alpha=0.7, label='Q1 Loss')\n",
        "axes[0].set_title('Q1 Loss')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(loss_df['step'], loss_df['loss_q2'], 'g-', alpha=0.7, label='Q2 Loss')\n",
        "axes[1].set_title('Q2 Loss')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].plot(loss_df['step'], loss_df['loss_q1'] + loss_df['loss_q2'], 'r--', alpha=0.7, label='Sum (Q1 + Q2)')\n",
        "axes[2].set_title('Sum (Q1 + Q2)')\n",
        "axes[2].set_xlabel('Step')\n",
        "axes[2].set_ylabel('Loss')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "actor_loss_df = loss_df[loss_df['actor_loss'].notna()]\n",
        "if len(actor_loss_df) > 0:\n",
        "    plt.plot(actor_loss_df['step'], actor_loss_df['actor_loss'], 'r-', alpha=0.7)\n",
        "    plt.title('Actor Loss')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'No actor loss data', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "    plt.title('Actor Loss (no data)')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(loss_df['step'], loss_df['buffer_size'], 'm-', alpha=0.7)\n",
        "plt.title('Buffer Size')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Size')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nn-laser-stabilizer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
