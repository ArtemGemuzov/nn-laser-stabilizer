experiment_name: td3_train_real_async
seed: 42 

defaults:
  - agent: agent
  - _self_

serial: # CHECK
  port: COM3 
  baudrate: 115200
  timeout: 0.1
  use_mock: false

env:
  setpoint: 1200 # CHECK

  reward:
    name: absolute # exponential absolute relative
    args:
      k: 20.0

  bounds:
    action:
      low: [0.0, 0.0, 0.0]
      high: [17.5, 55.0, 0.01]
    observation:
      low: [-inf, 0.0] 
      high: [inf, inf]
    reward:
      low: [-1.0]
      high: [1.0]

  force_min_value: 2000.0
  force_max_value: 4095.0
  
  default_min: 0.0
  default_max: 4095.0
  
  warmup_steps: 1000
  pretrain_blocks: 2500
  block_size: 200
  burn_in_steps: 100  

hydra:
  run:
    dir: experiments/${experiment_name}/${now:%Y-%m-%d}_${now:%H-%M-%S}

data:
  frames_per_batch: 1
  total_frames: 1_000_000_000

  buffer_size: 100_000
  min_data_for_training: 2000

train:
  batch_size: 64
  
  update_to_data: 10
  update_actor_freq: 2 

  total_train_steps: 1_000_000_000 # Обучение идет до прерывания через CTRL + C