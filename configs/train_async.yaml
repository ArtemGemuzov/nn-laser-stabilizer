experiment_name: td3_train_real_async
seed: 42 

defaults:
  - agent: agent
  - _self_

serial: # CHECK
  port: COM3 
  baudrate: 115200
  timeout: 0.1
  use_mock: false
  log_connection: true

env:
  setpoint: 1200 # CHECK

  reward:
    name: exponential # exponential absolute relative
    args:
      k: 20.0

  bounds:
    action:
      low: [-1.0, -1.0, -1.0]
      high: [1.0, 1.0, 1.0]
    observation:
      low: [-inf, 0.0] 
      high: [inf, inf]
    reward:
      low: [-1.0]
      high: [1.0]

  force_min_value: 2000
  force_max_value: 2500
  
  default_min: 0
  default_max: 4095
  
  lower_force_condition_threshold: 200
  upper_force_condition_threshold: 4000
  enforcement_steps: 1000
  
  warmup_steps: 1000
  pretrain_blocks: 2655 # TODO: рассчитывать через другие параметры
  block_size: 200
  burn_in_steps: 100  

hydra:
  run:
    dir: experiments/${experiment_name}/${now:%Y-%m-%d}_${now:%H-%M-%S}

data:
  frames_per_batch: 1
  total_frames: 1_000_000_000

  buffer_size: 100_000
  min_data_for_training: 2505

train:
  batch_size: 64
  
  update_to_data: 10
  update_actor_freq: 2 

  total_train_steps: 1_000_000_000 # Обучение идет до прерывания через CTRL + C